import os
import json
import certifi
import requests
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.chat_models import init_chat_model
from langchain.agents import create_agent

load_dotenv()
os.environ["SSL_CERT_FILE"] = certifi.where()


# -----------------------------
# AUTHENTICATION
# -----------------------------
def get_azure_access_token():
    tenant = os.getenv("AZURE_TENANT_ID")
    client_id = os.getenv("AZURE_CLIENT_ID")
    client_secret = os.getenv("AZURE_CLIENT_SECRET")

    url = f"https://login.microsoftonline.com/{tenant}/oauth2/v2.0/token"

    payload = {
        "client_id": client_id,
        "client_secret": client_secret,
        "scope": "https://analysis.windows.net/powerbi/api/.default",
        "grant_type": "client_credentials",
    }

    response = requests.post(url, data=payload)
    response.raise_for_status()
    return response.json()["access_token"]


# -----------------------------
# EXTRACT MCP SCHEMA
# -----------------------------
def extract_mcp_schema(result):
    for msg in result["messages"]:
        if msg.type == "tool":
            artifact = msg.artifact
            if artifact and "structured_content" in artifact:
                return artifact["structured_content"]
    return None


# -----------------------------
# GLOBAL CACHE (keeps schema loaded once)
# -----------------------------
class FinOpsContext:
    def __init__(self, model, agent_graph, schema):
        self.model = model
        self.agent_graph = agent_graph
        self.schema = schema


# -----------------------------
# INITIAL SETUP (RUNS ONCE)
# -----------------------------
async def finops_setup():

    print("üîê Getting Azure Token...")
    token = get_azure_access_token()

    servers = {
        "powerbi-remote": {
            "transport": "http",
            "url": "https://api.fabric.microsoft.com/v1/mcp/powerbi",
            "headers": {"Authorization": f"Bearer {token}"}
        }
    }

    client = MultiServerMCPClient(servers)
    tools = await client.get_tools()

    model = init_chat_model(
        os.getenv("MODEL"),
        model_provider="openai",
        api_key=os.getenv("GITHUB_TOKEN"),
        base_url=os.getenv("ENDPOINT"),
    )

    system_prompt = """
You are a FinOps assistant.

Use the schema to answer questions and generate DAX queries when needed.
Do NOT hallucinate tables or columns.
"""

    agent_graph = create_agent(model, tools, system_prompt=system_prompt, debug=False)

    workspace_id = os.getenv("POWERBI_WORKSPACE_ID")
    dataset_id = os.getenv("POWERBI_DATASET_ID")

    print("üìä Loading schema from MCP (one-time)...")

    schema_query = f"""
Inspect the semantic model.

Workspace ID: {workspace_id}
Dataset ID: {dataset_id}
"""

    result = await agent_graph.ainvoke(
        {"messages": [{"role": "user", "content": schema_query}]}
    )

    schema = extract_mcp_schema(result)

    print("‚úÖ Schema cached successfully")

    return FinOpsContext(model, agent_graph, schema)


# -----------------------------
# CHAT FUNCTION (CALLED PER MESSAGE)
# -----------------------------
async def chat_instance_stream(user_question, context: FinOpsContext):

    schema = context.schema
    model = context.model

    # Convert schema to string separately (avoids f-string confusion)
    schema_json = json.dumps(schema, indent=2)

    prompt = (
        "You are a FinOps expert.\n\n"
        "Answer the user question using this schema.\n"
        "If calculation is requested, generate a DAX query.\n\n"
        "Return format:\n\n"
        "Answer:\n"
        "<business explanation>\n\n"
        "DAX Query (if applicable):\n"
        "```DAX\n"
        "<query>\n"
        "```\n\n"
        "Schema:\n"
        + schema_json +
        "\n\nUser Question:\n"
        + user_question
    )

    response = await model.ainvoke(prompt)
    return response.content

hey in this code llm is generating dax querry and i want to run that dax querry in post api through my below file

import os
import requests
from dotenv import load_dotenv 

load_dotenv()


TENANT_ID = os.getenv("AZURE_TENANT_ID")
CLIENT_ID = os.getenv("AZURE_CLIENT_ID")
CLIENT_SECRET = os.getenv("AZURE_CLIENT_SECRET")

DATASET_ID = os.getenv("POWERBI_DATASET_ID")     # your dataset/semantic model id
# WORKSPACE_ID is not required for executeQueries, but you can keep it:
WORKSPACE_ID = os.getenv("POWERBI_WORKSPACE_ID") # optional

TOKEN_URL = f"https://login.microsoftonline.com/{TENANT_ID}/oauth2/v2.0/token"
SCOPE = "https://analysis.windows.net/powerbi/api/.default"

def get_access_token() -> str:
    payload = {
        "client_id": CLIENT_ID,
        "client_secret": CLIENT_SECRET,
        "scope": SCOPE,
        "grant_type": "client_credentials",
    }
    r = requests.post(TOKEN_URL, data=payload, timeout=30)
    r.raise_for_status()
    return r.json()["access_token"]

def execute_dax(dax_query: str) -> dict:
    token = get_access_token()

    url = f"https://api.powerbi.com/v1.0/myorg/datasets/{DATASET_ID}/executeQueries"  # Execute Queries API [1](https://teams.microsoft.com/l/message/19:12420f67-caa6-4fdb-b95b-d65e68df7140_d621cc14-de84-4ef6-8f24-d3d372afeb71@unq.gbl.spaces/1771405769321?context=%7B%22contextType%22:%22chat%22%7D)

    headers = {
        "Authorization": f"Bearer {token}",
        "Content-Type": "application/json",
    }

    body = {
        "queries": [{"query": dax_query}],
        "serializerSettings": {"includeNulls": True}
    }

    r = requests.post(url, headers=headers, json=body, timeout=60)
    r.raise_for_status()
    return r.json()

if __name__ == "__main__":
    dax = """
EVALUATE
VAR PrevMonthStart =
    EOMONTH(TODAY(), -2) + 1
VAR PrevMonthEnd =
    EOMONTH(TODAY(), -1)

VAR PrevPrevMonthStart =
    EOMONTH(TODAY(), -3) + 1
VAR PrevPrevMonthEnd =
    EOMONTH(TODAY(), -2)

VAR PrevMonthCost =
    CALCULATE(
        SUM('cost'[usd]),
        'calendar'[date] >= PrevMonthStart,
        'calendar'[date] <= PrevMonthEnd
    )

VAR PrevPrevMonthCost =
    CALCULATE(
        SUM('cost'[usd]),
        'calendar'[date] >= PrevPrevMonthStart,
        'calendar'[date] <= PrevPrevMonthEnd
    )

RETURN
ROW(
    "Previous Month USD", PrevMonthCost,
    "Month Before Previous USD", PrevPrevMonthCost,
    "Difference USD", PrevMonthCost - PrevPrevMonthCost,
    "Change %", DIVIDE(PrevMonthCost - PrevPrevMonthCost, PrevPrevMonthCost)
)
"""
    resp = execute_dax(dax)

    # rows are here:
    rows = resp["results"][0]["tables"][0]["rows"]
    print(rows)

so one of the thing i can do is that i can create a fn in my first script which generates the dax and then i can call that fn in my second script which calls post api. OR else if you have any other better approach to do this you can even prefer that
