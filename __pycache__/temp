import os
import asyncio
import certifi
import requests
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient

load_dotenv()

# Fix SSL issues in corporate environments
os.environ["SSL_CERT_FILE"] = certifi.where()


# -----------------------------
# AUTHENTICATION
# -----------------------------
def get_azure_access_token():
    tenant = os.getenv("AZURE_TENANT_ID")
    client_id = os.getenv("AZURE_CLIENT_ID")
    client_secret = os.getenv("AZURE_CLIENT_SECRET")

    if not tenant or not client_id or not client_secret:
        raise ValueError("Azure credentials missing in .env")

    url = f"https://login.microsoftonline.com/{tenant}/oauth2/v2.0/token"

    payload = {
        "client_id": client_id,
        "client_secret": client_secret,
        "scope": "https://analysis.windows.net/powerbi/api/.default",
        "grant_type": "client_credentials",
    }

    response = requests.post(url, data=payload)
    response.raise_for_status()

    print("‚úÖ Azure token generated successfully")
    return response.json()["access_token"]


# -----------------------------
# INTENT CLASSIFIER (STRICT)
# -----------------------------
def classify_intent(question: str) -> str:
    q = question.lower()

    if "schema" in q:
        return "schema"

    if "cost" in q or "spend" in q:
        return "cost"

    return "unknown"


# -----------------------------
# PRINT SCHEMA (ONLY WHEN ASKED)
# -----------------------------
def print_schema(schema):
    print("\n================ DATASET SCHEMA ================\n")

    for table in schema["Tables"]:
        print(f"üìÅ {table['Name']}")
        for col in table["Columns"]:
            print(f"   ‚îî‚îÄ {col['Name']} ({col['Type']})")
        print()


# -----------------------------
# MAIN EXECUTION (NO AGENT)
# -----------------------------
async def main():

    user_question = input("\nAsk your question: ").strip()

    intent = classify_intent(user_question)
    print(f"üîé Detected intent: {intent}")

    if intent == "unknown":
        print("[]")
        return

    print("üîê Generating Azure access token...")
    token = get_azure_access_token()

    servers = {
        "powerbi-remote": {
            "transport": "http",
            "url": "https://api.fabric.microsoft.com/v1/mcp/powerbi",
            "headers": {
                "Authorization": f"Bearer {token}"
            }
        }
    }

    print("üîå Connecting to MCP server...")
    client = MultiServerMCPClient(servers)

    tools = await client.get_tools()
    tool_map = {tool.name: tool for tool in tools}

    print(f"‚úÖ Connected. Available tools: {list(tool_map.keys())}")

    for t in tools:
        print("Tool: ", t.name)
        print("Schema: ", t.args_schema)
        print("------------------------------")

    dataset_id = os.getenv("POWERBI_DATASET_ID")

    # -----------------------------
    # SCHEMA REQUEST
    # -----------------------------
    if intent == "schema":
        try:
            tool = tool_map["GetSemanticModelSchema"]

            result = await tool.ainvoke({
                "artifactId": dataset_id
            })

            schema = result["structured_content"]
            print_schema(schema)

        except Exception:
            print("[]")

        return

    # -----------------------------
    # COST REQUEST (QUERY)
    # -----------------------------
    if intent == "cost":
        try:
            tool = tool_map["ExecuteQuery"]  # MCP generates DAX internally

            result = await tool.ainvoke({
                "artifactId": dataset_id,
                "query": user_question
            })

            print("\nüìä Query Result:\n")
            print(result)

        except Exception:
            # STRICT behavior: do NOT fallback
            print("[]")

        return


# -----------------------------
# ENTRY POINT
# -----------------------------
if __name__ == "__main__":
    asyncio.run(main())

after running this above code:


(mcp-help) PS C:\Users\KANSUL\mcp-help> python openAI_mcp.py
C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\_api\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.
  from pydantic.v1.fields import FieldInfo as FieldInfoV1

Ask your question: Fetch schema
üîé Detected intent: schema
üîê Generating Azure access token...
‚úÖ Azure token generated successfully
üîå Connecting to MCP server...
‚úÖ Connected. Available tools: ['ExecuteQuery', 'GenerateQuery', 'GetSemanticModelSchema']
Tool:  ExecuteQuery
Schema:  {'type': 'object', 'properties': {'artifactId': {'description': 'The GUID of the artifact (semantic model or report) to execute Dax query against.', 'type': 'string'}, 'daxQuery': {'description': 'The DAX query to execute against the underlying Power BI semantic model.', 'type': 'string'}, 'maxRows': {'description': 'The maximum number of rows to return (optional, default: 250, max: 1000)', 'type': ['integer', 'null'], 'default': None}}, 'required': ['artifactId', 'daxQuery']}
------------------------------
Tool:  GenerateQuery
Schema:  {'type': 'object', 'properties': {'artifactId': {'description': 'The GUID of the artifact (semantic model or report) to generate the Dax query on.', 'type': 'string'}, 'userInput': {'description': "The user's input for which the DAX query should be generated. This will be used to understand the intent and focus of the query.", 'type': 'string'}, 'schemaSelection': {'description': "Schema context containing the relevant tables, columns, and measures needed to answer the question. Include related tables that might be needed for joins or context, key columns for filtering/grouping, and measures for calculations. It's better to include slightly more than needed rather than too little.", 'type': 'object', 'properties': {'tables': {'description': "Array of tables that contain data relevant to the user's question. You must include tables that will be used in the DAX query.", 'type': ['array', 'null'], 'items': {'type': 'object', 'properties': {'name': {'description': 'Name of the table that contains relevant data', 'type': ['string', 'null']}, 'columns': {'description': "Column names from this table that are needed to answer the user's question. You must include columns that will be referenced in the DAX query or are needed for filtering/grouping.", 'type': ['array', 'null'], 'items': {'type': 'string'}}, 'measures': {'description': "Measure names from this table that are needed to answer the user's question. You must include measures that will be used in calculations or aggregations.", 'type': ['array', 'null'], 'items': {'type': 'string'}}}}}}}, 'chatHistory': {'description': "Optional chat history to provide context for the DAX generation. This should include user questions and assistant responses containing DAX queries. Use 'user' role for business questions and 'assistant' role for the corresponding DAX queries that were generated. This allows the DAX generation to understand what queries were previously generated and build upon them appropriately.", 'type': 'array', 'items': {'type': 'object', 'properties': {'role': {'description': "The role of the message author. Use 'user' for business questions and 'assistant' for DAX query responses.", 'type': 'string', 'enum': ['System', 'User', 'Assistant', 'Tool', 'Developer']}, 'content': {'description': 'The content of the message. For user messages, this should be the business question. For assistant messages, this should be the actual DAX query that was generated (including any comments).', 'type': ['string', 'null']}}}, 'default': None}}, 'required': ['artifactId', 'userInput', 'schemaSelection']}
------------------------------
Tool:  GetSemanticModelSchema
Schema:  {'type': 'object', 'properties': {'artifactId': {'description': 'The GUID of the artifact (semantic model or report) to fetch the schema for.', 'type': 'string'}}, 'required': ['artifactId']}
------------------------------
[]
