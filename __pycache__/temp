async def run_mcp_reasoning(model_with_tools, client, messages):
    """
    Executes the MCP reasoning loop:
    LLM → Tool Call → Execute → Feed Result Back → Repeat
    """

    while True:
        response = await model_with_tools.ainvoke(messages)

        # If no tool calls, we are done
        if not response.tool_calls:
            return response

        for call in response.tool_calls:
            tool_name = call["name"]
            tool_args = call["args"]

            print(f"\n⚙️ Executing MCP Tool: {tool_name}")
            print(f"Arguments: {tool_args}\n")

            # Find the MCP tool
            tool = next(t for t in await client.get_tools() if t.name == tool_name)

            # Execute against Fabric
            tool_result = await tool.ainvoke(tool_args)

            print(f"✅ Tool Result Received ({tool_name})")

            # Send result back to LLM
            messages.append(response)
            messages.append({
                "role": "tool",
                "name": tool_name,
                "content": str(tool_result)
            })
