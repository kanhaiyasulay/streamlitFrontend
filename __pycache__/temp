import os
import asyncio
import certifi
import requests
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from langchain.chat_models import init_chat_model
from langchain.agents import create_agent

load_dotenv()

# Fix SSL issues in corporate environments
os.environ["SSL_CERT_FILE"] = certifi.where()


def get_azure_access_token():
    """
    Generates Azure AD token using Service Principal
    """
    tenant = os.getenv("AZURE_TENANT_ID")
    client_id = os.getenv("AZURE_CLIENT_ID")
    client_secret = os.getenv("AZURE_CLIENT_SECRET")

    if not tenant or not client_id or not client_secret:
        raise ValueError("Azure credentials missing in .env")

    url = f"https://login.microsoftonline.com/{tenant}/oauth2/v2.0/token"

    payload = {
        "client_id": client_id,
        "client_secret": client_secret,
        "scope": "https://analysis.windows.net/powerbi/api/.default",
        "grant_type": "client_credentials",
    }

    response = requests.post(url, data=payload)
    response.raise_for_status()

    print("‚úÖ Azure token generated successfully")
    return response.json()["access_token"]


def extract_mcp_schema(result):
    """
    Extract ONLY the MCP structured payload (ignore LangChain metadata)
    """
    for msg in result["messages"]:
        if msg.type == "tool":
            artifact = msg.artifact
            if artifact and "structured_content" in artifact:
                return artifact["structured_content"]

    return None


def print_schema(schema):
    """
    Pretty print schema for debugging / validation
    """
    print("\n================ DATASET SCHEMA ================\n")

    print("üìä Tables:\n")
    for table in schema["Tables"]:
        print(f"üìÅ {table['Name']}")
        for col in table["Columns"]:
            print(f"   ‚îî‚îÄ {col['Name']} ({col['Type']})")
        print()

    print("\nüîó Relationships:\n")
    for rel in schema["ActiveRelationships"]:
        print(f"{rel['PK']}  --->  {rel['FK']}")


async def main():
    print("üîê Generating Azure access token...")
    token = get_azure_access_token()

    # Connect to Fabric MCP Endpoint
    servers = {
        "powerbi-remote": {
            "transport": "http",
            "url": "https://api.fabric.microsoft.com/v1/mcp/powerbi",
            "headers": {
                "Authorization": f"Bearer {token}"
            }
        }
    }

    print("üîå Connecting to MCP server...")
    client = MultiServerMCPClient(servers)

    tools = await client.get_tools()
    print(f"‚úÖ Connected. Discovered {len(tools)} MCP tools")

    # Initialize LLM (will be used later for reasoning)
    model = init_chat_model(
        os.getenv("MODEL"),
        model_provider="openai",
        api_key=os.getenv("GITHUB_TOKEN"),
        base_url=os.getenv("ENDPOINT"),
    )

    system_prompt = """
    You are a FinOps analyst working with Power BI semantic models through MCP.
    Always use MCP tools to inspect datasets. Never assume schema.
    """

    agent_graph = create_agent(model, tools, system_prompt=system_prompt, debug=False)

    workspace_id = os.getenv("POWERBI_WORKSPACE_ID")
    dataset_id = os.getenv("POWERBI_DATASET_ID")

    query = f"""
    Execute a DAX query using MCP.

    Workspace ID: {workspace_id}
    Dataset ID: {dataset_id}

    DAX:

    EVALUATE
    VAR LatestDate =
        CALCULATE(MAX('cost'[date]), ALL('cost'))

    RETURN
    SUMMARIZECOLUMNS(
        'cost'[date],
        "TotalCostUSD", CALCULATE(SUM('cost'[usd]), 'cost'[date] = LatestDate)
    )

    Explain the result briefly.
    """

    print("üìä Fetching semantic model schema...")
    result = await agent_graph.ainvoke(
        {"messages": [{"role": "user", "content": query}]}
    )

    # ‚úÖ Extract REAL DATA
    schema = extract_mcp_schema(result)

    if not schema:
        print("‚ùå No schema returned from MCP")
        return

    print_schema(schema)

    # You will reuse this schema for FinOps reasoning later
    print("\n‚úÖ MCP integration validated successfully.\n")


if __name__ == "__main__":
    asyncio.run(main())


python openAI_mcp.py
C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\_api\deprecation.py:25: UserWarning: Core Pydantic V1 functionality isn't compatible with Python 3.14 or greater.
  from pydantic.v1.fields import FieldInfo as FieldInfoV1
üîê Generating Azure access token...
‚úÖ Azure token generated successfully
üîå Connecting to MCP server...
‚úÖ Connected. Discovered 3 MCP tools
üìä Fetching semantic model schema...
Traceback (most recent call last):
  File "C:\Users\KANSUL\mcp-help\openAI_mcp.py", line 153, in <module>
    asyncio.run(main())
    ~~~~~~~~~~~^^^^^^^^
  File "C:\Users\KANSUL\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\runners.py", line 204, in run
    return runner.run(main)
           ~~~~~~~~~~^^^^^^
  File "C:\Users\KANSUL\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\runners.py", line 127, in run
    return self._loop.run_until_complete(task)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^
  File "C:\Users\KANSUL\AppData\Local\Python\pythoncore-3.14-64\Lib\asyncio\base_events.py", line 719, in run_until_complete
    return future.result()
           ~~~~~~~~~~~~~^^
  File "C:\Users\KANSUL\mcp-help\openAI_mcp.py", line 135, in main
    result = await agent_graph.ainvoke(
             ^^^^^^^^^^^^^^^^^^^^^^^^^^
        {"messages": [{"role": "user", "content": query}]}
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\pregel\main.py", line 3161, in ainvoke
    async for chunk in self.astream(
    ...<29 lines>...
            chunks.append(chunk)
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\pregel\main.py", line 2974, in astream
    async for _ in runner.atick(
    ...<13 lines>...
            yield o
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\pregel\_runner.py", line 304, in atick
    await arun_with_retry(
    ...<15 lines>...
    )
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\pregel\_retry.py", line 138, in arun_with_retry
    return await task.proc.ainvoke(task.input, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\_internal\_runnable.py", line 705, in ainvoke
    input = await asyncio.create_task(
            ^^^^^^^^^^^^^^^^^^^^^^^^^^
        step.ainvoke(input, config, **kwargs), context=context
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\_internal\_runnable.py", line 473, in ainvoke
    ret = await self.afunc(*args, **kwargs)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 846, in _afunc
    outputs = await asyncio.gather(*coros)
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 1177, in _arun_one
    return await self._execute_tool_async(tool_request, input_type, config)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 1126, in _execute_tool_async
    content = _handle_tool_error(e, flag=self._handle_tool_errors)
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 430, in _handle_tool_error
    content = flag(e)  # type: ignore [assignment, call-arg]
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 387, in _default_handle_tool_errors
    raise e
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langgraph\prebuilt\tool_node.py", line 1083, in _execute_tool_async
    response = await tool.ainvoke(call_args, config)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\tools\structured.py", line 70, in ainvoke
    return await super().ainvoke(input, config, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\tools\base.py", line 652, in ainvoke
    return await self.arun(tool_input, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\tools\base.py", line 1130, in arun
    raise error_to_raise
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\tools\base.py", line 1096, in arun
    response = await coro_with_context(coro, context)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_core\tools\structured.py", line 124, in _arun
    return await self.coroutine(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_mcp_adapters\tools.py", line 414, in call_tool
    return _convert_call_tool_result(call_tool_result)
  File "C:\Users\KANSUL\mcp-help\.venv\Lib\site-packages\langchain_mcp_adapters\tools.py", line 189, in _convert_call_tool_result
    raise ToolException(error_msg)
langchain_core.tools.base.ToolException: An error occurred invoking 'ExecuteQuery': DAX query execution failed: PowerBI service client received error HTTP response. HttpStatus: 401. PowerBIErrorCode: PowerBINotLicensedException. RootActivityId: fe29134d-ca60-4671-9c71-cb8bb8579e77.
During task with name 'tools' and id '801d0398-9c56-6dce-eb46-5c5f813dfcb0'
